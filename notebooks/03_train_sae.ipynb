{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 – Train a Sparse Autoencoder\n",
    "\n",
    "**Purpose:** Feature discovery. This is where SAEs stop being abstract.\n",
    "\n",
    "We train a sparse autoencoder on the cached MLP activations to learn interpretable features.\n",
    "\n",
    "**Sections:**\n",
    "1. Load cached activations\n",
    "2. Initialize SAE\n",
    "3. Train for a short run\n",
    "4. Plot: reconstruction loss vs step, sparsity vs step\n",
    "5. Save model\n",
    "\n",
    "---\n",
    "\n",
    "## What is an SAE?\n",
    "\n",
    "A **Sparse Autoencoder** learns to:\n",
    "- **Encode**: Map a 768-dim activation → 4096-dim sparse representation\n",
    "- **Decode**: Reconstruct the original activation from the sparse code\n",
    "\n",
    "The L1 penalty encourages sparsity — most features should be ~0 for any given input.\n",
    "\n",
    "**Why 4096 features for 768 dims?**  \n",
    "Overcomplete dictionaries can capture more fine-grained, interpretable directions than the original basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Load cached activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.chdir('/Users/poonam/projects/mechinterp-from-scratch')\n",
    "\n",
    "# Config\n",
    "CACHE_PATH = \"artifacts/cache/gpt2_l6_mlpout_fp16.mmap\"\n",
    "D_IN = 768\n",
    "D_SAE = 4096\n",
    "LR = 1e-3\n",
    "L1_COEF = 1e-3\n",
    "\n",
    "# Load memmap\n",
    "data = np.memmap(CACHE_PATH, dtype=np.float16, mode=\"r\")\n",
    "n_tokens = data.shape[0] // D_IN\n",
    "data = data.reshape(n_tokens, D_IN)\n",
    "\n",
    "print(f\"Loaded {n_tokens:,} activation vectors\")\n",
    "print(f\"Shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Initialize SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    \"\"\"Simple Sparse Autoencoder.\n",
    "    \n",
    "    Architecture:\n",
    "        encode: x → z = W_enc @ x + b_enc\n",
    "        activate: a = ReLU(z)  (sparse activations)\n",
    "        decode: x_hat = W_dec @ a\n",
    "    \"\"\"\n",
    "    def __init__(self, d_in: int, d_sae: int):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Linear(d_in, d_sae, bias=True)\n",
    "        self.dec = nn.Linear(d_sae, d_in, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.enc(x)\n",
    "        a = torch.relu(z)  # sparse activations\n",
    "        x_hat = self.dec(a)\n",
    "        return x_hat, a\n",
    "\n",
    "device = torch.device(\"cpu\")  # CPU is fine for small SAE training\n",
    "sae = SAE(D_IN, D_SAE).to(device)\n",
    "optimizer = AdamW(sae.parameters(), lr=LR)\n",
    "\n",
    "print(f\"SAE: {D_IN} → {D_SAE} → {D_IN}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in sae.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_batch(batch_size: int) -> torch.Tensor:\n",
    "    \"\"\"Sample random batch of activations.\"\"\"\n",
    "    idx = np.random.randint(0, n_tokens, size=(batch_size,))\n",
    "    x = torch.from_numpy(data[idx].astype(np.float32))\n",
    "    return x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training config\n",
    "N_STEPS = 2000\n",
    "BATCH_SIZE = 2048\n",
    "LOG_EVERY = 100\n",
    "\n",
    "# Tracking\n",
    "history = {\n",
    "    \"step\": [],\n",
    "    \"recon_loss\": [],\n",
    "    \"sparsity\": [],\n",
    "    \"total_loss\": []\n",
    "}\n",
    "\n",
    "print(f\"Training for {N_STEPS} steps, batch size {BATCH_SIZE}\")\n",
    "print(f\"L1 coefficient: {L1_COEF}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for step in range(N_STEPS):\n",
    "    x = sample_batch(BATCH_SIZE)\n",
    "    x_hat, a = sae(x)\n",
    "    \n",
    "    # Losses\n",
    "    recon_loss = torch.mean((x_hat - x) ** 2)\n",
    "    sparsity = torch.mean(torch.abs(a))\n",
    "    total_loss = recon_loss + L1_COEF * sparsity\n",
    "    \n",
    "    # Backward\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Log\n",
    "    if step % LOG_EVERY == 0:\n",
    "        history[\"step\"].append(step)\n",
    "        history[\"recon_loss\"].append(recon_loss.item())\n",
    "        history[\"sparsity\"].append(sparsity.item())\n",
    "        history[\"total_loss\"].append(total_loss.item())\n",
    "        \n",
    "        print(f\"step {step:4d} | recon: {recon_loss.item():.4f} | sparsity: {sparsity.item():.4f} | total: {total_loss.item():.4f}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Plot training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Reconstruction loss\n",
    "axes[0].plot(history[\"step\"], history[\"recon_loss\"], 'b-', linewidth=2)\n",
    "axes[0].set_xlabel(\"Step\")\n",
    "axes[0].set_ylabel(\"Reconstruction Loss (MSE)\")\n",
    "axes[0].set_title(\"Reconstruction Loss vs Step\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Sparsity\n",
    "axes[1].plot(history[\"step\"], history[\"sparsity\"], 'r-', linewidth=2)\n",
    "axes[1].set_xlabel(\"Step\")\n",
    "axes[1].set_ylabel(\"Mean |activation|\")\n",
    "axes[1].set_title(\"Sparsity Proxy vs Step\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sparsity more directly: what fraction of activations are ~zero?\n",
    "x_test = sample_batch(1000)\n",
    "_, a_test = sae(x_test)\n",
    "\n",
    "# Count near-zero activations (threshold 0.01)\n",
    "near_zero = (a_test.abs() < 0.01).float().mean().item()\n",
    "avg_active = (a_test > 0.01).float().sum(dim=1).mean().item()\n",
    "\n",
    "print(f\"Fraction of activations near zero: {near_zero:.1%}\")\n",
    "print(f\"Average active features per input: {avg_active:.1f} / {D_SAE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = \"artifacts/sae/sae.pt\"\n",
    "os.makedirs(os.path.dirname(SAVE_PATH), exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    \"state_dict\": sae.state_dict(),\n",
    "    \"d_in\": D_IN,\n",
    "    \"d_sae\": D_SAE,\n",
    "    \"l1_coef\": L1_COEF,\n",
    "    \"n_steps\": N_STEPS,\n",
    "    \"final_recon_loss\": history[\"recon_loss\"][-1],\n",
    "    \"final_sparsity\": history[\"sparsity\"][-1],\n",
    "}, SAVE_PATH)\n",
    "\n",
    "print(f\"Saved SAE to {SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Note: Not all features will be interpretable\n",
    "\n",
    "After training, you might expect every one of the 4096 features to correspond to a clean, interpretable concept. **This is not the case.**\n",
    "\n",
    "**Why some features remain uninterpretable:**\n",
    "\n",
    "1. **Polysemanticity residue**: Some features may still capture multiple unrelated concepts.\n",
    "\n",
    "2. **Noise features**: Some features may primarily capture noise or high-frequency patterns without semantic meaning.\n",
    "\n",
    "3. **Computational features**: The model may use some directions for intermediate computations that don't map to human concepts.\n",
    "\n",
    "4. **Insufficient training**: With more data and longer training, more features may become interpretable.\n",
    "\n",
    "5. **Wrong granularity**: Some concepts may require different scales (finer or coarser) than our SAE provides.\n",
    "\n",
    "**This is expected and okay.** The goal is to find *some* interpretable features, not to make all features interpretable. Even a small set of interpretable features can provide valuable insights into model behavior.\n",
    "\n",
    "**Next:** Use notebook 04 to browse features and look for interpretable ones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mechinterp-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
